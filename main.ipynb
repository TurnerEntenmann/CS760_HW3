{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import matplotlib.lines as mlines\n",
    "from sklearn import neighbors, metrics\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fxn for plotting\n",
    "def get_ax(figsize=(6,4)):\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fpr = [0, 0, 1/4, 2/4, 4/4]\n",
    "# tpr = [0, 2/6, 4/6, 6/6, 6/6]\n",
    "\n",
    "# ax=get_ax()\n",
    "\n",
    "# plt.plot(fpr, tpr, c=\"0\", marker=\".\")\n",
    "\n",
    "# # axies settings\n",
    "# fsize=15\n",
    "# plt.xticks(size=fsize-2)\n",
    "# plt.yticks(size=fsize-2)\n",
    "# plt.xlabel(\"False Positive Rate\", size=fsize)\n",
    "# plt.ylabel(\"True Positive Rate\", size=fsize)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"Plots/ROC1.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D is the name of the data file\n",
    "# returns a df with columns x_1, x_2, y of float values\n",
    "def read_data(D):\n",
    "    df = pd.read_csv(\"data/\"+D, sep = \" \", names = [\"x_1\", \"x_2\", \"y\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get D2z.txt into a dataframe\n",
    "D2z_df = read_data(\"D2z.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_i are floats, df is a datafram\n",
    "# returns predicted class based on nearest neighbor\n",
    "def oneNN(x_1, x_2, df):\n",
    "    # init vars to store best info\n",
    "    best_dist = None\n",
    "    best_y = 1\n",
    "    # loop through df\n",
    "    for i, row in df.iterrows():\n",
    "        # calculate euclidean distance\n",
    "        dist = np.sqrt((row[0]-x_1)**2+(row[1]-x_2)**2)\n",
    "        # if the distance is the first calculated, it is the best\n",
    "        if best_dist == None:\n",
    "            best_dist = dist\n",
    "            best_y = row[2]\n",
    "        # replace old best distance if we find a better one\n",
    "        elif dist < best_dist:\n",
    "            best_dist = dist\n",
    "            best_y = row[2]\n",
    "    return best_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make a grid, predict each point\n",
    "# d1 = {\"x_1\":[], \"x_2\":[], \"y\":[]}\n",
    "# grid_x = np.linspace(-2, 2, 20)\n",
    "# for x_1 in grid_x:\n",
    "#     for x_2 in grid_x:\n",
    "#         y = oneNN(x_1, x_2, D2z_df)\n",
    "#         d1[\"x_1\"].append(x_1)\n",
    "#         d1[\"x_2\"].append(x_2)\n",
    "#         d1[\"y\"].append(int(y))\n",
    "\n",
    "# boundary_df = pd.DataFrame(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make axies\n",
    "# ax = get_ax()\n",
    "\n",
    "# # set colors (colorblind friendly via https://yoshke.org/blog/colorblind-friendly-diagrams)\n",
    "# colors = {0: '#000000', 1: '#E69F00'}\n",
    "\n",
    "# # make plot\n",
    "# boundary_df.plot.scatter(x=\"x_1\", y=\"x_2\", c=boundary_df[\"y\"].map(colors), marker=\"s\", s=40, alpha=0.4, ax=ax)\n",
    "# D2z_df.plot.scatter(x=\"x_1\", y=\"x_2\", c=D2z_df[\"y\"].map(colors), alpha=0.8, ax=ax)\n",
    "\n",
    "# # plot settings\n",
    "# fsize = 15\n",
    "# # legend\n",
    "# b_dot = mlines.Line2D([], [], color='#000000', marker='s', linestyle='None',\n",
    "#                           markersize=10, label='0')\n",
    "# o_dot = mlines.Line2D([], [], color='#E69F00', marker='s', linestyle='None',\n",
    "#                           markersize=10, label='1')\n",
    "# ax.legend(handles=[b_dot, o_dot], fontsize=fsize, bbox_to_anchor=(1, 1), frameon=False)\n",
    "\n",
    "# # axies settings\n",
    "# plt.xticks(size=fsize-2)\n",
    "# plt.yticks(size=fsize-2)\n",
    "# plt.xlabel(\"$x_1$\", size=fsize)\n",
    "# plt.ylabel(\"$x_2$\", size=fsize)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"Plots/boundary_plot.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get emails.csv as a df\n",
    "emails_df = pd.read_csv(\"data/emails.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train and test dfs\n",
    "# train dfs dont need the 'email number' or 'prediction' columns\n",
    "# test dfs dont need the 'email number' column\n",
    "\n",
    "single_train_df = emails_df[:4000].drop([\"Email No.\", \"Prediction\"], axis=1)\n",
    "single_test_df = emails_df[4000:].drop(\"Email No.\", axis=1)\n",
    "\n",
    "f1_test_df = emails_df[:1000].drop(\"Email No.\", axis=1)\n",
    "f1_train_df = emails_df[1000:].drop(\"Email No.\", axis=1)\n",
    "\n",
    "f2_test_df = emails_df[1000:2000].drop(\"Email No.\", axis=1)\n",
    "f2_train_df = emails_df.iloc[np.r_[0:1000, 2000:5000]].drop(\"Email No.\", axis=1)\n",
    "\n",
    "f3_test_df = emails_df[2000:3000].drop(\"Email No.\", axis=1)\n",
    "f3_train_df = emails_df.iloc[np.r_[0:2000, 3000:5000]].drop(\"Email No.\", axis=1)\n",
    "\n",
    "f4_test_df = emails_df[3000:4000].drop(\"Email No.\", axis=1)\n",
    "f4_train_df = emails_df.iloc[np.r_[0:3000, 4000:5000]].drop(\"Email No.\", axis=1)\n",
    "\n",
    "f5_test_df = emails_df[4000:].drop(\"Email No.\", axis=1)\n",
    "f5_train_df = emails_df[:4000].drop(\"Email No.\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create the classifier\n",
    "# knn1 = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "# # train the classifier\n",
    "# knn1.fit(f1_train_df.drop(\"Prediction\", axis=1), f1_train_df[\"Prediction\"])\n",
    "# # make predictions\n",
    "# pred_1 = knn1.predict(f1_test_df.drop(\"Prediction\", axis=1))\n",
    "\n",
    "# # find and print the accuracy, precision and recall\n",
    "# acc_1 = metrics.accuracy_score(f1_test_df[\"Prediction\"], pred_1)\n",
    "# pre_1 = metrics.precision_score(f1_test_df[\"Prediction\"], pred_1)\n",
    "# rec_1 = metrics.recall_score(f1_test_df[\"Prediction\"], pred_1)\n",
    "# print(f\"fold 1: acc: {acc_1}, pre: {pre_1}, rec: {rec_1}\")\n",
    "\n",
    "# # these steps are repeated for the other folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn2 = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "# knn2.fit(f2_train_df.drop(\"Prediction\", axis=1), f2_train_df[\"Prediction\"])\n",
    "# pred_2 = knn2.predict(f2_test_df.drop(\"Prediction\", axis=1))\n",
    "# acc_2 = metrics.accuracy_score(f2_test_df[\"Prediction\"], pred_2)\n",
    "# pre_2 = metrics.precision_score(f2_test_df[\"Prediction\"], pred_2)\n",
    "# rec_2 = metrics.recall_score(f2_test_df[\"Prediction\"], pred_2)\n",
    "# print(f\"fold 2: acc: {acc_2}, pre: {pre_2}, rec: {rec_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn3 = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "# knn3.fit(f3_train_df.drop(\"Prediction\", axis=1), f3_train_df[\"Prediction\"])\n",
    "# pred_3 = knn3.predict(f3_test_df.drop(\"Prediction\", axis=1))\n",
    "# acc_3 = metrics.accuracy_score(f3_test_df[\"Prediction\"], pred_3)\n",
    "# pre_3 = metrics.precision_score(f3_test_df[\"Prediction\"], pred_3)\n",
    "# rec_3 = metrics.recall_score(f3_test_df[\"Prediction\"], pred_3)\n",
    "# print(f\"fold 3: acc: {acc_3}, pre: {pre_3}, rec: {rec_3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn4 = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "# knn4.fit(f4_train_df.drop(\"Prediction\", axis=1), f4_train_df[\"Prediction\"])\n",
    "# pred_4 = knn4.predict(f4_test_df.drop(\"Prediction\", axis=1))\n",
    "# acc_4 = metrics.accuracy_score(f4_test_df[\"Prediction\"], pred_4)\n",
    "# pre_4 = metrics.precision_score(f4_test_df[\"Prediction\"], pred_4)\n",
    "# rec_4 = metrics.recall_score(f4_test_df[\"Prediction\"], pred_4)\n",
    "# print(f\"fold 4: acc: {acc_4}, pre: {pre_4}, rec: {rec_4}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn5 = neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "# knn5.fit(f5_train_df.drop(\"Prediction\", axis=1), f5_train_df[\"Prediction\"])\n",
    "# pred_5 = knn5.predict(f5_test_df.drop(\"Prediction\", axis=1))\n",
    "# acc_5 = metrics.accuracy_score(f5_test_df[\"Prediction\"], pred_5)\n",
    "# pre_5 = metrics.precision_score(f5_test_df[\"Prediction\"], pred_5)\n",
    "# rec_5 = metrics.recall_score(f5_test_df[\"Prediction\"], pred_5)\n",
    "# print(f\"fold 5: acc: {acc_5}, pre: {pre_5}, rec: {rec_5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z is a number\n",
    "# returns sigmoid fxn of z\n",
    "def sigmoid(z):\n",
    "    return 1/(1+np.exp(-z))\n",
    "# x and theta are vectors, y is a number \n",
    "# returns gradient of the loss function for grad descent\n",
    "def gradient(x, theta, y):\n",
    "    return x * float((sigmoid(theta.T @ x) - y))\n",
    "\n",
    "# df is a data frame, rate is a number\n",
    "# returns the vector theta\n",
    "def grad_desc(df, rate):\n",
    "    # init theta as a zero vector\n",
    "    theta = np.zeros(len(df.drop(\"Prediction\", axis=1).iloc[0]))\n",
    "    # loop through the df\n",
    "    for i, row in df.iterrows():\n",
    "        # run one step of the grad descent algorithm\n",
    "        y = row[-1]\n",
    "        theta = theta - rate * gradient(row[:-1], theta, y)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test\n",
    "# df = pd.DataFrame({\"1\":[1], \"2\":[3], \"3\": [2], \"Prediction\":[1]})\n",
    "# grad_desc(df, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta is a vector, df is a dataframe\n",
    "# returns the accuracy, precision and recall\n",
    "def test_GD(theta, df):\n",
    "    # init true/false pos/neg variables\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "    # loop through df\n",
    "    for i, row in df.iterrows():\n",
    "        # tv is the actual y val\n",
    "        true_val = row[-1]\n",
    "        # see if the prediction is closer to 1 or 0\n",
    "        if sigmoid(f1_theta @ row[:-1]) >= 0.5:\n",
    "            # update relevant vars\n",
    "            if true_val == 1:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FP += 1\n",
    "        else:\n",
    "            # update relevant vars\n",
    "            if true_val == 1:\n",
    "                FN += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "    # calculate accuracy, precision and recall\n",
    "    acc = (TP + TN) / (TP + FP + TN + FN)\n",
    "    pre = TP / (TP + FP)\n",
    "    rec = TP / (TP + FN)\n",
    "    return acc, pre, rec\n",
    "\n",
    "# train and test are dfs, rate is a number\n",
    "# returns the accuracy, precision and recall\n",
    "def run_GD(train, test, rate):\n",
    "    # find theta\n",
    "    theta = grad_desc(train, rate)\n",
    "    # test theta\n",
    "    return test_GD(theta, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-4cf578e5414c>:3: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-z))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.843, 0.9, 0.5052631578947369)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_GD(f1_train_df, f1_test_df, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-4cf578e5414c>:3: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-z))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.823, 0.8333333333333334, 0.45126353790613716)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_GD(f2_train_df, f2_test_df, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-4cf578e5414c>:3: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-z))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.819, 0.912, 0.4014084507042254)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_GD(f3_train_df, f3_test_df, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-4cf578e5414c>:3: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-z))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.819, 0.900709219858156, 0.43197278911564624)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_GD(f4_train_df, f4_test_df, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-4cf578e5414c>:3: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1+np.exp(-z))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.779, 0.8346456692913385, 0.3464052287581699)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_GD(f5_train_df, f5_test_df, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
